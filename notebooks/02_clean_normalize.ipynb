{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Clean and Normalize\n",
        "\n",
        "## Overview\n",
        "Standardize compounds, derive stints, attach tyre age, remove outliers.\n",
        "\n",
        "## Inputs\n",
        "- data/raw/*_laps.parquet\n",
        "\n",
        "## Outputs\n",
        "- data/interim/laps_interim.parquet\n",
        "- data/interim/stints_interim.parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
        "\n",
        "import pandas as pd\n",
        "from f1ts import config, io_flat, clean, validation\n",
        "\n",
        "config.ensure_dirs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Raw Laps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3 lap files\n",
            "  Loaded 2023_3_R_laps.parquet: 882 laps\n",
            "  Loaded 2023_1_R_laps.parquet: 1,035 laps\n",
            "  Loaded 2023_2_R_laps.parquet: 904 laps\n",
            "\n",
            "Total laps: 2,821\n"
          ]
        }
      ],
      "source": [
        "raw_dir = config.paths()['data_raw']\n",
        "laps_files = list(raw_dir.glob('*_laps.parquet'))\n",
        "\n",
        "print(f\"Found {len(laps_files)} lap files\")\n",
        "\n",
        "all_laps = []\n",
        "for laps_file in laps_files:\n",
        "    laps = pd.read_parquet(laps_file)\n",
        "    all_laps.append(laps)\n",
        "    print(f\"  Loaded {laps_file.name}: {len(laps):,} laps\")\n",
        "\n",
        "laps_raw = pd.concat(all_laps, ignore_index=True)\n",
        "print(f\"\\nTotal laps: {len(laps_raw):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform: Clean Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting cleaning pipeline...\n",
            "✓ Standardized compounds: 2,821 laps\n",
            "✓ Derived 224 stints\n",
            "✓ Attached tyre age\n",
            "✓ Fixed data types\n",
            "Removing 288 outlier laps (10.2%)\n",
            "✓ Removed outliers: 2,533 laps remaining\n",
            "\n",
            "Cleaned laps: 2,533\n",
            "Stints derived: 224\n"
          ]
        }
      ],
      "source": [
        "laps_clean, stints = clean.clean_pipeline(laps_raw)\n",
        "\n",
        "print(f\"\\nCleaned laps: {len(laps_clean):,}\")\n",
        "print(f\"Stints derived: {len(stints):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Schema validation passed for laps_interim\n",
            "✓ No NA values in required columns for laps_interim\n",
            "✓ Categorical validation passed for laps_interim.compound\n",
            "\n",
            "✓ All validations passed\n"
          ]
        }
      ],
      "source": [
        "# Validate schema\n",
        "required_lap_cols = ['session_key', 'driver', 'lap', 'compound', 'stint_id', 'tyre_age_laps']\n",
        "validation.validate_schema(laps_clean, required_lap_cols, name='laps_interim')\n",
        "\n",
        "# Validate no NAs in key columns\n",
        "validation.assert_no_na(laps_clean, ['session_key', 'driver', 'lap', 'compound'], name='laps_interim')\n",
        "\n",
        "# Check compounds\n",
        "validation.validate_categorical(laps_clean, 'compound', set(config.VALID_COMPOUNDS), name='laps_interim')\n",
        "\n",
        "print('\\n✓ All validations passed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved laps_interim.parquet: 2,533 rows, 13 cols\n",
            "✓ Saved stints_interim.parquet: 224 rows, 7 cols\n",
            "\n",
            "✓ Saved interim data\n"
          ]
        }
      ],
      "source": [
        "interim_dir = config.paths()['data_interim']\n",
        "\n",
        "io_flat.write_parquet(laps_clean, interim_dir / 'laps_interim.parquet')\n",
        "io_flat.write_parquet(stints, interim_dir / 'stints_interim.parquet')\n",
        "\n",
        "print('\\n✓ Saved interim data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Repro Notes\n",
        "\n",
        "- Standardized compounds\n",
        "- Derived stints based on pit stops and compound changes\n",
        "- Attached tyre age\n",
        "- Removed outliers using MAD\n",
        "- All validations passed"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.1)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
